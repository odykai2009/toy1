{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h2>Regression<h2></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Get Started\n",
    "\n",
    "- Make sure opalite is running on Chrome or FireFox.\n",
    "- Click *Cell* and *Run All* to kick it off (find it in the menu on top of this page) \n",
    "    - See the little circle on the upper right corner. It will be filled when the kernel is running and hollow when idle\n",
    "    - If see the warnings of \"Widget Javascript not detected.\", wait a while and then click *Cell* and *Run All* again.\n",
    "- Click *show/hide the raw code* button to show or hide the code\n",
    "- Click *Insert* and *Insert Cell Above/Below* to insert a code block and start to write your own customized code (need to show code first)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>\n",
       "code_show=true; \n",
       "function code_toggle() {\n",
       " if (code_show){\n",
       " $('div.input').hide();\n",
       " } else {\n",
       " $('div.input').show();\n",
       " }\n",
       " code_show = !code_show\n",
       "} \n",
       "$( document ).ready(code_toggle);\n",
       "</script>\n",
       "<form action=\"javascript:code_toggle()\"><input type=\"submit\" value=\"Click here to show/hide the raw code.\"></form>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# toggle code\n",
    "\n",
    "from IPython.display import HTML\n",
    "HTML('''<script>\n",
    "code_show=true; \n",
    "function code_toggle() {\n",
    " if (code_show){\n",
    " $('div.input').hide();\n",
    " } else {\n",
    " $('div.input').show();\n",
    " }\n",
    " code_show = !code_show\n",
    "} \n",
    "$( document ).ready(code_toggle);\n",
    "</script>\n",
    "<form action=\"javascript:code_toggle()\"><input type=\"submit\" value=\"Click here to show/hide the raw code.\"></form>''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosave disabled\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load packages and check package versions\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import re\n",
    "import datetime\n",
    "import getpass\n",
    "import logging\n",
    "import sklearn\n",
    "from sklearn.base import clone\n",
    "#import forest_ci as fci\n",
    "#sys.path.append('C:\\\\Users\\\\bihan\\\\eclipse\\\\workspace-python\\\\mltemplate')\n",
    "\n",
    "os.environ['MLTEMPLATE_LOG_PATH'] = os.environ['HOME']\n",
    "\n",
    "%matplotlib inline\n",
    "%config IPCompleter.greedy=True\n",
    "%autosave 0\n",
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.graph_objs as go\n",
    "from mltemplate.mldata import MLData\n",
    "from mltemplate.mlmodel import MLModel\n",
    "from ipywidgets import *\n",
    "from IPython.display import display, clear_output, Image, Javascript, SVG\n",
    "from plotly.offline import init_notebook_mode, iplot\n",
    "from plotly.tools import FigureFactory as FF       \n",
    "\n",
    "# Initialize data and model object instances\n",
    "mld = MLData(regret=True)\n",
    "mlm = MLModel()\n",
    "\n",
    "# for plotly\n",
    "init_notebook_mode(connected=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from blkbms.bms import BMS\n",
    "# from blkbms.message import Message, SemaphoreMsgBody\n",
    "# from blkcore.dates.utils import now\n",
    "# import getpass\n",
    "# user = getpass.getuser()\n",
    "# #print('Sending gen_stat')\n",
    "# testmap = {'client': 'ADS',\n",
    "#           'module': 'ADS-OPAL',\n",
    "#           'submodule': 'Opal-regression',\n",
    "#           'tag_def': 'version-1.0',\n",
    "#           'key_1': user}\n",
    "# with BMS() as conn:    \n",
    "#     bms_message = Message()\n",
    "#     bms_message.init(SemaphoreMsgBody(testmap), 103)\n",
    "#     bms_message.get_header().set_msg_subtype(7)\n",
    "#     try:        \n",
    "#         response = conn.send(bms_message, timeout=100)\n",
    "#     except:\n",
    "#         pass\n",
    "# #print('Done Sending gen_stat : ' + str(testmap))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'blkbms'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-de7c36b08a3d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mblkbms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbms\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBMS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mblkbms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSemaphoreMsgBody\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mblkcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdates\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgetpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0muser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetpass\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetuser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'blkbms'"
     ]
    }
   ],
   "source": [
    "# from blkbms.bms import BMS\n",
    "# from blkbms.message import Message, SemaphoreMsgBody\n",
    "# from blkcore.dates.utils import now\n",
    "# import getpass\n",
    "# user = getpass.getuser()\n",
    "\n",
    "# def perf_log(client='ADS-OPAL', module='Opal-regression', submodule='start', tag_def='version-1.0', user=user):\n",
    "#     testmap = {'client': client,\n",
    "#               'module': module,\n",
    "#               'submodule': submodule,\n",
    "#               'tag_def': tag_def,\n",
    "#               'key_1': user}\n",
    "#     with BMS() as conn:    \n",
    "#         bms_message = Message()\n",
    "#         bms_message.init(SemaphoreMsgBody(testmap), 103)\n",
    "#         bms_message.get_header().set_msg_subtype(7)\n",
    "#         try:        \n",
    "#             response = conn.send(bms_message, timeout=100)\n",
    "#         except:\n",
    "#             pass    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# perf_log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import functools\n",
    "import scipy.interpolate\n",
    "import itertools\n",
    "import math\n",
    "#import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "from scipy.signal import fftconvolve\n",
    "from scipy.stats import norm\n",
    "import copy\n",
    "from sklearn.ensemble.forest import _generate_sample_indices\n",
    "\n",
    "__all__ = [\"gfit\", \"gbayes\",\"calibrateEB\", \"calc_inbag\", \"random_forest_error\", \"_bias_correction\",\n",
    "           \"_core_computation\"]\n",
    "\n",
    "'''\n",
    "from .due import _due, _BibTeX\n",
    "_due.cite(_BibTeX(\"\"\"\n",
    "@ARTICLE{Wager2014-wn,\n",
    "  title       = \"Two modeling strategies for empirical Bayes estimation.\",\n",
    "  author      = Efron, Bradley\n",
    "  journal     = \"Stat. Sci.\",\n",
    "  volume      =  29,\n",
    "  number      =  2,\n",
    "  pages       = \"285--301\",\n",
    "  month       =  feb,\n",
    "  year        =  2014,}\"\"\"),\n",
    "          description=(\"Confidence Intervals for Random Forests:\",\n",
    "                       \"The Jackknife and the Infinitesimal Jackknife\"),\n",
    "          path='forestci')\n",
    "'''\n",
    "\n",
    "def gfit(X, sigma, p=5, nbin=1000, unif_fraction=0.1):\n",
    "    \"\"\"\n",
    "    Fit an empirical Bayes prior in the hierarchical model\n",
    "        mu ~ G, X ~ N(mu, sigma^2)\n",
    "    Parameters\n",
    "    ----------\n",
    "    X: ndarray\n",
    "        A 1D array of observations\n",
    "    sigma: float\n",
    "        noise estimate on X\n",
    "    p: int\n",
    "        tuning parameter -- number of parameters used to fit G\n",
    "    nbin: int\n",
    "        tuning parameter -- number of bins used for discrete approximation\n",
    "    unif_fraction: float\n",
    "        tuning parameter -- fraction of G modeled as \"slab\"\n",
    "    Returns\n",
    "    -------\n",
    "    An array of the posterior density estimate g\n",
    "    Notes\n",
    "    -----\n",
    "    .. [Efron2014] B Efron. \"Two modeling strategies for empirical Bayes\n",
    "        estimation.\" Stat. Sci., 29(2): 285–301, 2014.\n",
    "    \"\"\"\n",
    "    #global xvals, XX\n",
    "\n",
    "    min_x = min(min(X) - 2 * np.std(X,ddof=1), 0)\n",
    "    max_x = max(max(X) + 2 * np.std(X,ddof=1), np.std(X,ddof=1))\n",
    "    xvals = np.linspace(min_x, max_x, nbin)\n",
    "    binw = (max_x - min_x) / (nbin - 1)\n",
    "    \n",
    "    zero_idx = max(np.where(xvals <= 0)[0])\n",
    "    noise_kernel = norm().pdf(xvals / sigma) * binw / sigma\n",
    "\n",
    "    if zero_idx > 0:\n",
    "        noise_rotate = noise_kernel[list(np.arange(zero_idx, len(xvals))) +\n",
    "                                    list(np.arange(0, zero_idx))]\n",
    "    else:\n",
    "        noise_rotate = noise_kernel\n",
    "\n",
    "    XX = np.zeros((p, len(xvals)), dtype=np.float)\n",
    "    for ind, exp in enumerate(range(1,p+1)):\n",
    "        mask = np.ones_like(xvals)\n",
    "        mask[np.where(xvals <= 0)[0]] = 0\n",
    "        XX[ind, :] = pow(xvals, exp) * mask\n",
    "    XX = XX.T\n",
    "\n",
    "    def neg_loglik(eta):\n",
    "        mask = np.ones_like(xvals)\n",
    "        mask[np.where(xvals <= 0)[0]] = 0\n",
    "        g_eta_raw = np.exp(np.dot(XX, eta)) * mask\n",
    "        if ((sum(g_eta_raw) == math.inf) |(sum(g_eta_raw) <= 100 * np.finfo(np.double).tiny)):\n",
    "            return (1000 * (len(X) + sum(eta ** 2)))\n",
    "\n",
    "        g_eta_main = g_eta_raw / sum(g_eta_raw)\n",
    "        g_eta = (1 - unif_fraction) * g_eta_main + unif_fraction * mask / sum(mask)\n",
    "        f_eta = fftconvolve(g_eta, noise_rotate, mode='same') \n",
    "        return np.sum(np.interp(X, xvals, -np.log(np.maximum(f_eta, 0.0000001))))\n",
    "\n",
    "\n",
    "    eta_hat = minimize(neg_loglik, list(itertools.repeat(-1, p))).x  ###\n",
    "    g_eta_raw = np.exp(np.dot(XX, eta_hat)) * mask\n",
    "    g_eta_main = g_eta_raw / sum(g_eta_raw)\n",
    "    g_eta = ((1 - unif_fraction) * g_eta_main + unif_fraction * mask) / sum(mask)\n",
    "\n",
    "    return xvals, g_eta\n",
    "\n",
    "def gbayes(x0, g_est, sigma):\n",
    "    \"\"\"\n",
    "    Bayes posterior estimation with Gaussian noise\n",
    "    Parameters\n",
    "    ----------\n",
    "    x0: ndarray\n",
    "        an observation\n",
    "    g_est: float\n",
    "        a prior density, as returned by gfit\n",
    "    sigma: int\n",
    "        noise estimate\n",
    "    Returns\n",
    "    -------\n",
    "    An array of the posterior estimate E[mu | x0]\n",
    "    Notes\n",
    "    -----\n",
    "     .. [Efron2014] B Efron. \"Two modeling strategies for empirical Bayes\n",
    "          estimation.\" Stat. Sci., 29(2): 285–301, 2014.\n",
    "    \"\"\"\n",
    "\n",
    "    Kx = norm().pdf((g_est[0] - x0) / sigma)\n",
    "    post = Kx * g_est[1]\n",
    "    post = post/ sum(post)\n",
    "    return sum(post * g_est[0])\n",
    "\n",
    "def calibrateEB(variances, sigma2, speedup=False):\n",
    "    \"\"\"\n",
    "    Empirical Bayes calibration of noisy variance estimates\n",
    "    Parameters\n",
    "    ----------\n",
    "    vars: ndarray\n",
    "        list of variance estimates\n",
    "    sigma2: int\n",
    "        estimate of the Monte Carlo noise in vars\n",
    "    speedup: boolean\n",
    "        whether to use interpolation to speed up computations\n",
    "    Returns\n",
    "    -------\n",
    "    An array of the calibrated variance estimates\n",
    "    \"\"\"\n",
    "\n",
    "    if (sigma2 <= 0 or min(variances) == max(variances)):\n",
    "        return(np.maximum(variances, 0))\n",
    "    \n",
    "    sigma = sigma2**0.5\n",
    "    eb_prior = gfit(variances, sigma)\n",
    "    \n",
    "    if speedup:\n",
    "        # If there are many points use interpolation to speed up computations\n",
    "        calib_x = np.percentile(variances, np.arange(0, 100.1, .1))\n",
    "        #calib_y = list(map(gbayes(xx, eb_prior, sigma), calib_x))\n",
    "        calib_y = list(map(functools.partial(gbayes, g_est=eb_prior, sigma=sigma),\n",
    "                      calib_x))\n",
    "        calib_all = np.interp(variances, calib_x, calib_y)\n",
    "    else: \n",
    "        calib_all = list(map(functools.partial(gbayes, g_est=eb_prior, sigma=sigma),\n",
    "                        variances))\n",
    "        \n",
    "    return(calib_all)\n",
    "\n",
    "\n",
    "def calc_inbag(n_samples, forest):\n",
    "    \"\"\"\n",
    "    Derive samples used to create trees in scikit-learn RandomForest objects.\n",
    "\n",
    "    Recovers the samples in each tree from the random state of that tree using\n",
    "    :func:`forest._generate_sample_indices`.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_samples : int\n",
    "        The number of samples used to fit the scikit-learn RandomForest object.\n",
    "\n",
    "    forest : RandomForest\n",
    "        Regressor or Classifier object that is already fit by scikit-learn.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Array that records how many times a data point was placed in a tree.\n",
    "    Columns are individual trees. Rows are the number of times a sample was\n",
    "    used in a tree.\n",
    "    \"\"\"\n",
    "    if not forest.bootstrap:\n",
    "        e_s = \"Cannot calculate the inbag from a forest that has \"\n",
    "        e_s = \" bootstrap=False\"\n",
    "        raise ValueError(e_s)\n",
    "\n",
    "    n_trees = forest.n_estimators\n",
    "    inbag = np.zeros((n_samples, n_trees))\n",
    "    sample_idx = []\n",
    "    for t_idx in range(n_trees):\n",
    "        sample_idx.append(\n",
    "            _generate_sample_indices(forest.estimators_[t_idx].random_state,\n",
    "                                     n_samples))\n",
    "        inbag[:, t_idx] = np.bincount(sample_idx[-1], minlength=n_samples)\n",
    "    return inbag\n",
    "\n",
    "\n",
    "def _core_computation(X_train, X_test, inbag, pred_centered, n_trees):\n",
    "    cov_hat = np.zeros((X_train.shape[0], X_test.shape[0]))\n",
    "\n",
    "    for t_idx in range(n_trees):\n",
    "        inbag_r = (inbag[:, t_idx] - 1).reshape(-1, 1)\n",
    "        pred_c_r = pred_centered.T[t_idx].reshape(1, -1)\n",
    "        cov_hat += np.dot(inbag_r, pred_c_r) / n_trees\n",
    "    V_IJ = np.sum(cov_hat ** 2, 0)\n",
    "    return V_IJ\n",
    "\n",
    "\n",
    "def _bias_correction(V_IJ, inbag, pred_centered, n_trees):\n",
    "    n_train_samples = inbag.shape[0]\n",
    "    n_var = np.mean(np.square(inbag[0:n_trees]).mean(axis=1).T.view() -\n",
    "                    np.square(inbag[0:n_trees].mean(axis=1)).T.view())\n",
    "    boot_var = np.square(pred_centered).sum(axis=1) / n_trees\n",
    "    bias_correction = n_train_samples * n_var * boot_var / n_trees\n",
    "    V_IJ_unbiased = V_IJ - bias_correction\n",
    "    return V_IJ_unbiased\n",
    "\n",
    "\n",
    "def random_forest_error(forest, X_train, X_test, inbag=None, calibrate = True, speedup=False):\n",
    "    \"\"\"\n",
    "    Calculates error bars from scikit-learn RandomForest estimators.\n",
    "\n",
    "    RandomForest is a regressor or classifier object\n",
    "    this variance can be used to plot error bars for RandomForest objects\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    forest : RandomForest\n",
    "        Regressor or Classifier object.\n",
    "\n",
    "    X : ndarray\n",
    "        An array with shape (n_sample, n_features).\n",
    "\n",
    "    inbag : ndarray (optional)\n",
    "        The inbag matrix that fit the data. If set to `None` (default) it\n",
    "        will be inferred from the forest. However, this only works for trees\n",
    "        for which bootstrapping was set to `True`. That is, if sampling was\n",
    "        done with replacement. Otherwise, users need to provide their own\n",
    "        inbag matrix.\n",
    "\n",
    "    calibrate: boolean (default True)\n",
    "        Whether to apply calibration to mitigate Monte Carlo noise\n",
    "        if calibrate = FALSE, some variance estimates may be negative\n",
    "        due to Monte Carlo effects if the number of trees in rfrgr is too small\n",
    "    \n",
    "    speedup: boolean (default False)\n",
    "        Whether to use interpolation to speedup calculation\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    An array with the unbiased sampling variance (V_IJ_unbiased)\n",
    "    for a RandomForest object.\n",
    "\n",
    "    See Also\n",
    "    ----------\n",
    "    :func:`calc_inbag`\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    The calculation of error is based on the infinitesimal jackknife variance,\n",
    "    as described in [Wager2014]_ and is a Python implementation of the R code\n",
    "    provided at: https://github.com/swager/randomForestCI\n",
    "\n",
    "    .. [Wager2014] S. Wager, T. Hastie, B. Efron. \"Confidence Intervals for\n",
    "       Random Forests: The Jackknife and the Infinitesimal Jackknife\", Journal\n",
    "       of Machine Learning Research vol. 15, pp. 1625-1651, 2014.\n",
    "    \"\"\"\n",
    "    \n",
    "    ####### just to temporarily suppresssing warnings\n",
    "    import warnings\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    ####### end of suppresssing warnings\n",
    "    \n",
    "    \n",
    "    if inbag is None:\n",
    "        inbag = calc_inbag(X_train.shape[0], forest)\n",
    "\n",
    "    pred = np.array([tree.predict(X_test) for tree in forest]).T\n",
    "    pred_mean = np.mean(pred, 0)\n",
    "    pred_centered = pred - pred_mean\n",
    "    n_trees = forest.n_estimators\n",
    "    V_IJ = _core_computation(X_train, X_test, inbag, pred_centered, n_trees)\n",
    "    V_IJ_unbiased = _bias_correction(V_IJ, inbag, pred_centered, n_trees)\n",
    "\n",
    "    # Correct for cases where resampling is done without replacement:\n",
    "    if np.max(inbag) == 1:\n",
    "        variance_inflation = 1 / (1 - np.mean(inbag)) ** 2\n",
    "        V_IJ_unbiased *= variance_inflation\n",
    "\n",
    "    if not calibrate:\n",
    "        return V_IJ_unbiased\n",
    "\n",
    "    if len(V_IJ_unbiased) <= 20:\n",
    "        calibrate = False\n",
    "        print(\"No calibration with n <= 20\")\n",
    "        return V_IJ_unbiased\n",
    "\n",
    "    if calibrate:\n",
    "        calibration_ratio = 2\n",
    "        n_sample = np.ceil(n_trees / calibration_ratio)\n",
    "        new_forest = copy.deepcopy(forest)\n",
    "        new_forest.estimators_ = np.random.permutation(new_forest.estimators_)[:int(n_sample)]\n",
    "        new_forest.n_estimators = int(n_sample)\n",
    "\n",
    "        results_ss = random_forest_error(new_forest, X_train, X_test, calibrate=False)\n",
    "        # Use this second set of variance estimates\n",
    "        # to estimate scale of Monte Carlo noise\n",
    "        sigma2_ss = np.mean((results_ss - V_IJ_unbiased)**2)\n",
    "        delta = n_sample / n_trees\n",
    "        sigma2 = (delta**2 + (1 - delta)**2) / (2 * (1 - delta)**2) * sigma2_ss\n",
    "\n",
    "        # Use Monte Carlo noise scale estimate for empirical Bayes calibration\n",
    "        if speedup:\n",
    "            V_IJ_calibrated = calibrateEB(V_IJ_unbiased, sigma2, speedup=True)\n",
    "        else:\n",
    "            V_IJ_calibrated = calibrateEB(V_IJ_unbiased, sigma2)\n",
    "\n",
    "        return V_IJ_calibrated\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# log usage\n",
    "\n",
    "# LOG_PATH = r'P:\\Proj\\public\\production_engineering\\data_science\\opalite_staging\\log'\n",
    "#if os.environ.get('MLTEMPLATE_LOG_PATH'):\n",
    "#    LOG_PATH = os.environ.get('MLTEMPLATE_LOG_PATH')\n",
    "LOG_PATH = os.environ.get('HOME')\n",
    "\n",
    "logger = logging.getLogger('opalite')\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "logger.handlers = []\n",
    "formatter = logging.Formatter('%(asctime)s, {}, %(message)s'.format(getpass.getuser()))\n",
    "fh = logging.FileHandler(os.path.join(LOG_PATH, 'log.csv'), mode='a')\n",
    "fh.setLevel(logging.INFO)\n",
    "fh.setFormatter(formatter)\n",
    "logger.addHandler(fh)\n",
    "\n",
    "logger.info('started')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Basic Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# display settings\n",
    "\n",
    "# widgets\n",
    "row_layout = Layout(display='flex', flex_flow='row', align_items='center')\n",
    "col_layout = dict(display='flex', flex_flow='column', justify_content='space-between', width='auto')\n",
    "\n",
    "def leftm(m=10):\n",
    "    '''Set left margin'''\n",
    "    return '0px 0px 0px {}px'.format(m)\n",
    "\n",
    "max_col = IntSlider(value=50, max=100, width='600px')\n",
    "max_row = IntSlider(value=100, max=250, width='600px')\n",
    "\n",
    "bs_row1 = Box([Label('Max Columns to Display:', layout=Layout(width='200px')),  max_col], layout=row_layout)\n",
    "bs_row2 = Box([Label('Max Rows to Display:', layout=Layout(width='200px')),  max_row], layout=row_layout)\n",
    "display(Box([bs_row1, bs_row2], layout=Layout(**col_layout)))\n",
    "\n",
    "# function\n",
    "pd.options.display.max_columns = max_col.value\n",
    "pd.options.display.max_rows = max_row.value\n",
    "\n",
    "def chg_setting(chg):\n",
    "    '''Change basic settings.'''\n",
    "    pd.options.display.max_rows = max_row.value\n",
    "    pd.options.display.max_columns = max_col.value\n",
    "\n",
    "max_col.observe(chg_setting, names='value')\n",
    "max_row.observe(chg_setting, names='value')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Data\n",
    "- accept .csv, .xls or .xlsx file (with single sheet) \n",
    "- data file path: it's using relative file path; by default it's the same directory as this notebook\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "\n",
    "# widgets\n",
    "# PATH = Text(description='Path:', width='800px', value='share')\n",
    "filepath = Text(description='File Path:', value='')\n",
    "loaddata_button = Button(description=\"Load Data\", button_style='success', margin=leftm(650))\n",
    "prog = FloatProgress(value=0, min=0, max=10, step=1, description='Progress:',\n",
    "                     margin=leftm(550), width='250px')\n",
    "display(filepath, loaddata_button, prog)\n",
    "\n",
    "# functions\n",
    "def loaddata(b):\n",
    "    '''Load data.'''\n",
    "    clear_output()\n",
    "    prog.value = 0\n",
    "    prog.description = 'Start...'\n",
    "    filepath_ = filepath.value # os.path.join(PATH.value, filename.value)\n",
    "    mld.read_data(filepath_)  # read data\n",
    "    prog.value = 5\n",
    "    prog.description = 'In Progress...'\n",
    "    mld.save_current()  # save a copy of current snapshot\n",
    "    prog.value = 10\n",
    "    prog.description = 'Done!'\n",
    "    mld.infer_categorical()\n",
    "    clear_output()\n",
    "    print('\\n', 'Data Head')\n",
    "    display(mld.head())  # display data head\n",
    "    print('\\n', 'Data Tail')\n",
    "    display(mld.tail())  # display data tail\n",
    "    print('\\n', 'Summary Statistics')    \n",
    "    display(mld.get_summary())  # display summary statistics\n",
    "    logger.info('loaded data')\n",
    "    \n",
    "loaddata_button.on_click(loaddata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Explore Data\n",
    "\n",
    "- You can plot a subset of the data by giving filtering criterion like these:\n",
    "    - currency == 'USD'\n",
    "    - bondtype != 'CLO'\n",
    "    - oas < 100 and oas > -50\n",
    "    - sec_type == 'SUB' or sec_type == 'SENIOR'\n",
    "    - sec_group not in ['CMO', 'CMBS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Select Graph\n",
    "\n",
    "# widgets\n",
    "chart_select = ToggleButtons(\n",
    "    options=['Pie Chart', 'Histogram', 'Box Plot', 'Cross Tab', 'Scatter Plot', 'Correlations'],\n",
    "    tooltips=['Visualize single categorical variable', 'Visualize single numerical variable',\n",
    "             'Visualize the relation between numerical and categorical variables',\n",
    "             'Visualize the relation between two categorical variables',\n",
    "             'Visualize pairwise distributions among a group of numerical variables',\n",
    "             'Visualize pairwise correlations among a group of numerical variables'],\n",
    "    value='Correlations', \n",
    "    margin=leftm()\n",
    ")\n",
    "\n",
    "display(HBox([Label('Graph Type: '), chart_select], layout=Layout(margin='0px 0px 30px 0px')))\n",
    "\n",
    "# functions\n",
    "grph = HTML('')\n",
    "\n",
    "def switch_chart(chg):\n",
    "    '''Switch between graph type.'''\n",
    "    global grph\n",
    "    clear_output()\n",
    "    grph.close()\n",
    "    grph = graph_mapping[chart_select.value]()\n",
    "    display(grph)\n",
    "\n",
    "chart_select.observe(switch_chart, names='value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Pie chart\n",
    "\n",
    "# widgets\n",
    "def make_pie():\n",
    "    '''create widgets for pie chart'''\n",
    "    global pie_filter, pie_select, pie_limit, group_less_freq, pieb\n",
    "    pie_filter = Text(value='', width='500px')\n",
    "    pie_select = Dropdown(options=mld.get_header(sort=True), height='30px', width='200px',\n",
    "                          margin=leftm())\n",
    "    pie_limit = IntText(value=20, width='70px')\n",
    "    group_less_freq = Checkbox(value=False)\n",
    "    pieb = Button(description=\"Plot\", button_style='success', width='70px', height='30px',\n",
    "                  margin=leftm(20))\n",
    "    \n",
    "    row0 = Box([HTML('<h4>Pie Chart - Visualize Distributions of Categorical Variables</h4>')],\n",
    "                layout=Layout(display='flex', flex_flow='row', align_items='center',\n",
    "                              justify_content='center', width='90%'))\n",
    "    row1 = Box([Label('Filter by Criterion: ', layout=Layout(width='200px')), pie_filter, pieb], layout=row_layout)\n",
    "    row2 = Box([Label('Select a Categorical Column: ', layout=Layout(width='200px')), pie_select,\n",
    "                Label('Limit on # of Values: ', layout=Layout(width='200px'), margin=leftm(20)), pie_limit], layout=row_layout)\n",
    "    row3 = Box([Label('Group Everything Below the Limit as \"others\": ', layout=Layout(width='400px')), group_less_freq],\n",
    "                layout=row_layout)\n",
    "    pie_chart = Box([row0, row1, row2, row3], layout=Layout(**col_layout),\n",
    "                    height='160px')\n",
    "\n",
    "    pie_select.observe(plot_pie, names='value')\n",
    "    pieb.on_click(plot_pie)\n",
    "    return pie_chart\n",
    "\n",
    "\n",
    "# functions\n",
    "def plot_pie(chg):\n",
    "    '''plot the pie chart'''\n",
    "    clear_output()\n",
    "    if pie_filter.value.strip() != '':\n",
    "        try:\n",
    "            vc = mld.query_chain(pie_filter.value).ct_freq(pie_select.value, group_less_freq.value,\n",
    "                                                           pie_limit.value)\n",
    "            vc.astype('category').cat.remove_unused_categories(True)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            vc = mld.ct_freq(pie_select.value, group_less_freq.value, pie_limit.value)\n",
    "    else:\n",
    "        vc = mld.ct_freq(pie_select.value, group_less_freq.value, pie_limit.value)\n",
    "    trace = go.Pie(labels=list(vc.index), values=vc.values)\n",
    "    figp = go.Figure(data=go.Data([trace]),\n",
    "                     layout=dict(title='Break Down of {}'.format(pie_select.value.upper())))\n",
    "    iplot(figp)\n",
    "    logger.info('plotted pie')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Histogram\n",
    "\n",
    "# widgets\n",
    "def make_hist():\n",
    "    '''make widgets for histogram'''\n",
    "    global hist_filter, histb, hist_select, hist_min, hist_max, hist_bins\n",
    "    hist_filter = Text(value='', width='500px')\n",
    "    histb = Button(description=\"Plot\", button_style='success', width='70px', height='30px',\n",
    "                   margin=leftm(20))\n",
    "    hist_select = Dropdown(options=mld.get_header(['int', 'float'], sort=True), height='30px',\n",
    "                           width='200px', margin=leftm())\n",
    "    hist_min = FloatText(value=float('-Inf'), width='70px')\n",
    "    hist_max = FloatText(value=float('Inf'), width='70px')\n",
    "    hist_bins = IntText(value=10, width='70px')\n",
    "    \n",
    "    row0 = Box([HTML('<h4>Histogram - Visualize Distributions of Numerical Variables</h4>')],\n",
    "                layout=Layout(display='flex', flex_flow='row', align_items='center',\n",
    "                              justify_content='center', width='90%'))\n",
    "    row1 = Box([Label('Filter by Criterion: ', layout=Layout(width='200px')), hist_filter, histb], layout=row_layout)\n",
    "    \n",
    "    row2 = Box([Label('Select a Numerical Column: ', layout=Layout(width='200px')), hist_select], layout=row_layout)\n",
    "    row3 = Box([Label('Min: ', layout=Layout(width='200px')), hist_min, Label('Max: ', margin=leftm(20)), hist_max,\n",
    "                Label('# of Bins: ', margin=leftm(20)), hist_bins], layout=row_layout)\n",
    "\n",
    "    hist_chart = Box([row0, row1, row2, row3], layout=Layout(**col_layout), height='160px')\n",
    "    \n",
    "    hist_select.observe(plot_hist_new_col)\n",
    "    histb.on_click(plot_hist)\n",
    "    return hist_chart\n",
    "\n",
    "\n",
    "# functions\n",
    "def plot_hist_new_col(chg):\n",
    "    '''plot histogram when switching columns'''\n",
    "    hist_min.value = float('-Inf')\n",
    "    hist_max.value = float('Inf')\n",
    "    plot_hist(chg)\n",
    "    \n",
    "def plot_hist(chg):\n",
    "    '''plot histogram'''\n",
    "    clear_output()\n",
    "    if hist_filter.value.strip() != '':\n",
    "        x = mld.query(hist_filter.value)[hist_select.value]\n",
    "    else:\n",
    "        x = mld.data[hist_select.value]\n",
    "    n = len(x)\n",
    "    x = x[x > hist_min.value]\n",
    "    x = x[x < hist_max.value]\n",
    "    print('Percentage covered (after filtering): {:.2f}%'.format(len(x) / n * 100))\n",
    "    if hist_min.value == float('-Inf'):\n",
    "        hist_min.value = np.round(np.min(x), 2) - 1\n",
    "    if hist_max.value == float('Inf'):\n",
    "        hist_max.value = np.round(np.max(x), 2) + 1\n",
    "\n",
    "    size = (hist_max.value - hist_min.value) / hist_bins.value\n",
    "    trh = go.Histogram(x=x, histnorm='percent', marker=dict(color='rgb(0,0,100)'),\n",
    "                       xbins=dict(start=hist_min.value - 0.5, size=size, end=hist_max.value + 0.5))\n",
    "\n",
    "    layout = dict(bargap= 0.015, hovermode= 'x',\n",
    "                  title='Histogram for {}'.format(hist_select.value.upper()),\n",
    "                  yaxis= dict(title='Percentage (%)', autorange= True, showticklabels= True))\n",
    "    figh = go.Figure(data=go.Data([trh]), layout=layout)\n",
    "    iplot(figh)\n",
    "    logger.info('plotted histogram')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Box plot\n",
    "\n",
    "# widgets\n",
    "def make_boxp():\n",
    "    '''Make widgets for box plot.'''\n",
    "    global box_filter, boxb, box_select_cat, box_select_num\n",
    "    box_filter = Text(value='', width='500px')\n",
    "    boxb = Button(description=\"Plot\", button_style='success', width='70px', height='30px',\n",
    "                  margin=leftm(20))\n",
    "    box_select_cat = Dropdown(options=mld.get_header('category', sort=True), height='30px',\n",
    "                              width='200px', margin=leftm())\n",
    "    box_select_num = Dropdown(options=mld.get_header(['int', 'float'], sort=True), height='30px',\n",
    "                              width='200px', margin=leftm())\n",
    "\n",
    "    row0 = Box([HTML('<h4>Box Plot - Visualize Relations between Numerical and Categorical '\n",
    "                     'Variables</h4>')],\n",
    "                layout=Layout(display='flex', flex_flow='row', align_items='center',\n",
    "                              justify_content='center', width='90%'))\n",
    "    row1 = Box([Label('Filter by Criterion: ', layout=Layout(width='200px')), box_filter, boxb], layout=row_layout)\n",
    "    row2 = Box([Label('Select y Axis: ', layout=Layout(width='200px')), box_select_num, \n",
    "                Label('Select x Axis: ', margin=leftm(20), layout=Layout(width='200px')),\n",
    "                box_select_cat], layout=row_layout)\n",
    "    box_chart = Box([row0, row1, row2], layout=Layout(**col_layout), height='120px')\n",
    "    box_select_cat.observe(plot_box, names='value')\n",
    "    box_select_num.observe(plot_box, names='value')\n",
    "    boxb.on_click(plot_box)\n",
    "    return box_chart\n",
    "\n",
    "\n",
    "# functions\n",
    "def plot_box(chg):\n",
    "    '''Generate box plot.'''\n",
    "    clear_output()\n",
    "    if box_select_cat.value is not None and box_select_num.value is not None:\n",
    "        temp_data = mld.data\n",
    "        if box_filter.value.strip() != '':\n",
    "            temp_data = mld.query(box_filter.value)\n",
    "        names = list(temp_data[box_select_cat.value].unique())\n",
    "        temp = []\n",
    "        for name in names:\n",
    "            mask = temp_data[box_select_cat.value] == name\n",
    "            temp.append(go.Box(y=list(temp_data.ix[mask, box_select_num.value]), name=name, showlegend=False))\n",
    "        figb = go.Figure(data=go.Data(temp),\n",
    "                         layout=dict(title='Box Plot: {} by {}'.\\\n",
    "                                     format(box_select_num.value.upper(),\n",
    "                                            box_select_cat.value.upper())))\n",
    "        iplot(figb)\n",
    "        logger.info('plotted box')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Cross Tab\n",
    "\n",
    "# widgets\n",
    "def make_xtab():\n",
    "    '''Make widgets for cross tab plot.'''\n",
    "    global xtab_filter, xtabb, xtab_select_x, xtab_select_y, xtab_pct\n",
    "    xtab_filter = Text(value='', width='500px')\n",
    "    xtabb = Button(description=\"Plot\", button_style='success', width='70px', height='30px',\n",
    "                  margin=leftm(20))\n",
    "    xtab_select_x = Dropdown(options=mld.get_header('category', sort=True), height='30px',\n",
    "                             width='200px', margin=leftm())\n",
    "    xtab_select_y = Dropdown(options=mld.get_header('category', sort=True), height='30px',\n",
    "                             width='200px', margin=leftm())\n",
    "    xtab_pct = Checkbox(value=True)\n",
    "\n",
    "    row0 = Box([HTML('<h4>Cross Tab - Visualize Relations between Two Categorical Variables</h4>')],\n",
    "                layout=Layout(display='flex', flex_flow='row', align_items='center',\n",
    "                              justify_content='center', width='90%'))\n",
    "    row1 = Box([Label('Filter by Criterion: ', layout=Layout(width='200px')), xtab_filter, xtabb], layout=row_layout)\n",
    "    row2 = Box([Label('Select y Axis: ', layout=Layout(width='200px')), xtab_select_y, \n",
    "                Label('Select x Axis: ', margin=leftm(20), layout=Layout(width='200px')),\n",
    "                xtab_select_x,], layout=row_layout)\n",
    "    row3 = Box([Label('Show as percentage: ', layout=Layout(width='200px')), xtab_pct], layout=row_layout)\n",
    "    xtab_chart = Box([row0, row1, row2, row3], layout=Layout(**col_layout), height='160px')\n",
    "    \n",
    "    xtab_select_x.observe(plot_xtab, names='value')\n",
    "    xtab_select_y.observe(plot_xtab, names='value')\n",
    "    xtabb.on_click(plot_xtab)\n",
    "    return xtab_chart\n",
    "\n",
    "\n",
    "# functions\n",
    "def plot_xtab(chg):\n",
    "    '''Generate cross tab.'''\n",
    "    clear_output()\n",
    "    x, y, normalize = xtab_select_x.value, xtab_select_y.value, xtab_pct.value\n",
    "\n",
    "    if xtab_filter.value.strip() != '':\n",
    "        temp_data = mld.query(xtab_filter.value)\n",
    "    else:\n",
    "        temp_data = mld.data\n",
    "        \n",
    "    temp_data[x].cat.remove_unused_categories(True)    \n",
    "    temp_data[y].cat.remove_unused_categories(True)\n",
    "\n",
    "    if normalize:\n",
    "        temp = temp_data.groupby(x)[y].value_counts(normalize=True)\n",
    "        vals = list(temp.index.levels[1])\n",
    "        temp = (temp.unstack(1, fill_value=0) * 100).round(2).reset_index()\n",
    "    else:\n",
    "        temp = temp_data.groupby(x)[y].value_counts()\n",
    "        vals = list(temp.index.levels[1])\n",
    "        temp = temp.unstack(1, fill_value=0).round(2).reset_index()\n",
    "        \n",
    "    #vals = pd.Series(temp_data[y].unique()).dropna()\n",
    "    data = []\n",
    "    for val in vals:\n",
    "        data.append(go.Bar(x=temp[x], y=temp[val], name=val))\n",
    "\n",
    "    layout = go.Layout(barmode='stack')\n",
    "    if normalize:\n",
    "        layout.yaxis.title='Percentage (%)'\n",
    "    else:\n",
    "        layout.yaxis.title='Frequency'\n",
    "\n",
    "    fig = go.Figure(data=data, layout=layout)\n",
    "    iplot(fig)\n",
    "    logger.info('plotted cross-tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Scatter Plot\n",
    "\n",
    "# widgets\n",
    "def make_scatter():\n",
    "    '''Make widgets for scatter plot.'''\n",
    "    global sp_filter, spb, sp_height, sp_select, sp_ccol\n",
    "    num_cols = mld.get_header(['int', 'float'], sort=True)\n",
    "    sp_filter = Text(value='', width='500px')\n",
    "    spb = Button(description=\"Plot\", button_style='success', width='70px', height='30px',\n",
    "                 margin=leftm(20))\n",
    "    sp_height = np.min([300, np.max([len(num_cols) * 15, 100])])\n",
    "    sp_select = SelectMultiple(options=num_cols, margin=leftm(),\n",
    "                               height='{}px'.format(sp_height))\n",
    "    sp_ccol = Dropdown(options=[None] + mld.get_header('category', sort=True), height='30px', width='200px', margin=leftm())\n",
    "\n",
    "    row0 = Box([HTML('<h4>Scatter Plot - Visualize Pairwise Distributions among a Group of Numerical '\n",
    "                     'Variables</h4>')],\n",
    "                layout=Layout(display='flex', flex_flow='row', align_items='center',\n",
    "                              justify_content='center', width='90%'))\n",
    "    row1 = Box([Label('Filter by Criterion: ', layout=Layout(width='200px')), sp_filter, spb], layout=row_layout)\n",
    "    row2 = Box([Label(\"Select Columns: \", layout=Layout(width='200px')), sp_select, Label(\"Group by: \", margin=leftm(30)), sp_ccol],\n",
    "                layout=row_layout)\n",
    "    scatter_chart = Box([row0, row1, row2], layout=Layout(**col_layout),\n",
    "                        height='{}px'.format(sp_height + 110))\n",
    "    spb.on_click(plot_scatter)\n",
    "    return scatter_chart\n",
    "\n",
    "\n",
    "# functions\n",
    "def plot_scatter(chg):\n",
    "    '''Generate scatter plot.'''\n",
    "    clear_output()\n",
    "\n",
    "    if sp_filter.value.strip() != '':\n",
    "        temp_data = mld.query(sp_filter.value).copy(True)\n",
    "    else:\n",
    "        temp_data = mld.data.copy(True)\n",
    "    \n",
    "    sel_cols = list(sp_select.value)\n",
    "    if sp_ccol.value is not None:\n",
    "        temp_data[sp_ccol.value].cat.remove_unused_categories(True)\n",
    "        temp_data[sp_ccol.value] = temp_data[sp_ccol.value].astype('object')\n",
    "        sel_cols.append(sp_ccol.value)\n",
    "\n",
    "    temp = temp_data[sel_cols]\n",
    "    \n",
    "    fig = FF.create_scatterplotmatrix(temp, index=sp_ccol.value, diag='histogram', height=800,\n",
    "                                      width=800)\n",
    "    iplot(fig)\n",
    "    logger.info('plotted scatter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Correlations\n",
    "\n",
    "# widgets\n",
    "def make_cor():\n",
    "    '''Make widgets for correlations plot.'''\n",
    "    global cor_filter, corb, cor_height, cor_select\n",
    "    num_cols = mld.get_header(['int', 'float'], sort=True)\n",
    "    cor_filter = Text(value='', width='500px')\n",
    "    corb = Button(description=\"Plot\", button_style='success', width='70px', height='30px',\n",
    "                  margin=leftm(20))\n",
    "    cor_height = np.min([300, np.max([len(num_cols) * 15, 100])])\n",
    "    cor_select = SelectMultiple(options=num_cols, margin=leftm(),\n",
    "                                height='{}px'.format(cor_height))\n",
    "    row0 = Box([HTML('<h4>Correlations - Visualize Correlations among a Group of Numerical Variables</h4>')],\n",
    "                layout=Layout(display='flex', flex_flow='row', align_items='center',\n",
    "                              justify_content='center', width='90%'))\n",
    "    row1 = Box([Label('Filter by Criterion: ', layout=Layout(width='200px')), cor_filter, corb], layout=row_layout)\n",
    "    row2 = Box([Label(\"Select Columns: \", layout=Layout(width='200px')), cor_select], layout=row_layout)\n",
    "    cor_chart = Box([row0, row1, row2], layout=Layout(**col_layout),\n",
    "                    height='{}px'.format(cor_height + 100))\n",
    "    corb.on_click(plot_cor)\n",
    "    return cor_chart\n",
    "\n",
    "\n",
    "# functions\n",
    "def plot_cor(chg):\n",
    "    '''Generate correlations plot.'''\n",
    "    clear_output()\n",
    "    \n",
    "    if cor_filter.value.strip() != '':\n",
    "        temp_data = mld.query(cor_filter.value).copy(True)\n",
    "    else:\n",
    "        temp_data = mld.data.copy(True)\n",
    "    \n",
    "    sel_cols = list(cor_select.value)\n",
    "    x, y = sel_cols, list(reversed(sel_cols))\n",
    "\n",
    "    corr = temp_data[sel_cols].corr().round(2)\n",
    "    z = np.flipud(corr.values)\n",
    "    annotations = []\n",
    "    for n, row in enumerate(z):\n",
    "        for m, val in enumerate(row):\n",
    "            var = z[n][m]\n",
    "            annotations.append(\n",
    "                dict(\n",
    "                    text=str(val),\n",
    "                    x=x[m], y=y[n],\n",
    "                    xref='x1', yref='y1',\n",
    "                    font=dict(color='black'),\n",
    "                    showarrow=False)\n",
    "                )\n",
    "\n",
    "    colorscale = [[0, 'rgba(255,0,0,0.3)'], [0.5, 'rgba(255,255,0,0.3)'], [1, 'rgba(0,255,0,0.3)']]\n",
    "    trace = go.Heatmap(x=x, y=y, z=z, zmin=-1, zmax=1, colorscale=colorscale, showscale=True)\n",
    "\n",
    "    fig = go.Figure(data=[trace])\n",
    "    fig['layout'].update(\n",
    "        title=\"Correlations\",\n",
    "        annotations=annotations,\n",
    "        xaxis=dict(ticks=''),\n",
    "        yaxis=dict(ticks='', ticksuffix='  '),\n",
    "        width=700,\n",
    "        height=700,\n",
    "        autosize=False\n",
    "    )\n",
    "    \n",
    "    iplot(fig)\n",
    "    logger.info('plotted correlation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "graph_mapping = {'Pie Chart': make_pie, 'Histogram': make_hist, 'Box Plot': make_boxp,\n",
    "                 'Cross Tab': make_xtab, 'Scatter Plot': make_scatter, 'Correlations': make_cor}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Clean Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Select Processing Function\n",
    "\n",
    "# widgets\n",
    "pros_select = ToggleButtons(\n",
    "    options=['Drop Columns', 'Filter Rows', 'Handle Outlier', 'Convert Dates', 'Handle Missing Value',\n",
    "             'Parse String'], value='Parse String', margin=leftm())\n",
    "\n",
    "undob = Button(description='Undo Previous Action', button_style='info', width='160px')\n",
    "torawb = Button(description='Restore to Original', button_style='warning', width='150px',\n",
    "                margin=leftm())\n",
    "savedatab = Button(description='Current Data -> CSV', button_style='success', width='150px',\n",
    "                   margin=leftm(70))\n",
    "savesumb = Button(description='Summary Stat -> CSV', button_style='success', width='160px',\n",
    "                  margin=leftm())\n",
    "\n",
    "pros = HTML('')\n",
    "\n",
    "display(Box([undob, torawb, savedatab, savesumb],\n",
    "            layout=Layout(display='flex', flex_flow='row', align_items='center',\n",
    "                          margin='0px 0px 20px 0px')))\n",
    "display(HBox([Label('Select: '), pros_select], layout=Layout(margin='0px 0px 30px 0px')))\n",
    "\n",
    "\n",
    "# functions\n",
    "def switch_pros(chg):\n",
    "    '''Switch between processing functions.'''\n",
    "    global pros\n",
    "    clear_output()\n",
    "    pros.close()\n",
    "    pros = pros_mapping[pros_select.value]()\n",
    "    display(pros)\n",
    "\n",
    "def undo(b):\n",
    "    '''Undo previous step.'''\n",
    "    clear_output()\n",
    "    mld.go_back()\n",
    "    print('\\nRestored data back to previous step.')\n",
    "    print('\\nSummary Statistics')\n",
    "    display(mld.get_summary(['dtype', 'column name']))\n",
    "\n",
    "def to_raw(b):\n",
    "    '''Restore to original data.'''\n",
    "    clear_output()\n",
    "    mld.data = mld.data_snapshot.copy(deep=True)\n",
    "    print('\\nRestored data back to original.')\n",
    "    print('\\nSummary Statistics')\n",
    "    display(mld.get_summary(['dtype', 'column name']))\n",
    "\n",
    "def save_data(b):\n",
    "    '''Save data to csv.'''\n",
    "    clear_output()\n",
    "    mld.data.to_csv('data.csv', index=False)\n",
    "    print('Data are saved to {}'.format(os.path.join(os.getcwd(), 'data.csv')))\n",
    "\n",
    "def save_summary(b):\n",
    "    '''Save summary statistics to csv.'''\n",
    "    clear_output()\n",
    "    mld.get_summary().to_csv('data_summary.csv', index=False)\n",
    "    print('Summary statistics are saved to {}'.format(os.path.join(os.getcwd(), 'data_summary.csv')))\n",
    "\n",
    "pros_select.observe(switch_pros, names='value')\n",
    "undob.on_click(undo)\n",
    "torawb.on_click(to_raw)\n",
    "savedatab.on_click(save_data)\n",
    "savesumb.on_click(save_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Drop columns\n",
    "\n",
    "# widgets\n",
    "def make_drop():\n",
    "    '''make widgets for drop_columns'''\n",
    "    global select_cols, drop_button\n",
    "    select_cols = SelectMultiple(options=mld.get_header(sort=True), \n",
    "                                 height= '{}px'.\\\n",
    "                                 format(np.min([300, np.max([len(mld.data.columns) * 15, 100])])), \n",
    "                                 margin=leftm(20))\n",
    "    drop_button = Button(description=\"Drop Columns\", button_style='success',\n",
    "                         margin=\"20px 0px 0px 50px\")\n",
    "    drop_button.on_click(drop_cols)\n",
    "    select_cols.observe(display_selected_col, names='value')\n",
    "    return HBox([Label(\"Select Columns\", layout=Layout(width='200px')), select_cols, drop_button])\n",
    "\n",
    "\n",
    "# functions\n",
    "def display_selected_col(chg):\n",
    "    clear_output()\n",
    "    print('\\nColumns to be dropped: ')\n",
    "    print(select_cols.value, '\\n')\n",
    "\n",
    "def drop_cols(b):\n",
    "    mld.drop_cols(select_cols.value)\n",
    "    select_cols.options = mld.get_header(sort=True)\n",
    "    clear_output()\n",
    "    print('\\nSummary Statistics')\n",
    "    display(mld.get_summary('dtype'))\n",
    "    logger.info('drop columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Filter rows\n",
    "\n",
    "# widgets\n",
    "def make_filter():\n",
    "    '''make widgets for filter_rows'''\n",
    "    global filter_expr\n",
    "    filter_expr = Text(width='500px')\n",
    "    filterb = Button(description=\"Filter Rows\", button_style='success', margin=leftm(650),\n",
    "                     width='100px')\n",
    "    row1 = Box([Label(\"Filter Rows by Criterion (result will persist): \", layout=Layout(width='400px')), filter_expr],\n",
    "               layout=row_layout)\n",
    "    row2 = Box([HTML(''' Examples:\n",
    "                    <ul>\n",
    "                        <li>currency == 'USD'</li>\n",
    "                        <li>bondtype != 'CLO'</li>\n",
    "                        <li>oas < 100 and oas > -50</li>\n",
    "                        <li>sec_type == 'SUB' or sec_type == 'SENIOR'\n",
    "                        <li>sec_group not in ['CMO', 'CMBS']\n",
    "                    </ul>\n",
    "                ''')], layout=row_layout)\n",
    "    row3 = Box([filterb], layout=row_layout)\n",
    "    filterb.on_click(filter_rows)\n",
    "    return Box([row1, row2, row3], layout=Layout(**col_layout), height='190px')\n",
    "\n",
    "# functions\n",
    "def filter_rows(b):\n",
    "    '''filter rows'''\n",
    "    clear_output()\n",
    "    print('\\nBefore Transformation')\n",
    "    print('Data Shape: {}'.format(mld.shape()))\n",
    "    mld.query(filter_expr.value, inplace=True)\n",
    "    print('\\nAfter Transformation')\n",
    "    print('Data Shape: {}'.format(mld.shape()))\n",
    "    print('\\nSummary Statistics')\n",
    "    display(mld.get_summary('dtype'))\n",
    "    logger.info('filter rows')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Handle outliers\n",
    "\n",
    "# widgets\n",
    "def make_outlier():\n",
    "    '''Make widgets for handle_outlier.'''\n",
    "    global outlier_select, outlier_radio, outlier_lp, outlier_up\n",
    "    outlier_select = Dropdown(options=mld.get_header(['float', 'int'], sort=True), height='30px',\n",
    "                              width='200px', margin=leftm())\n",
    "    outlier_radio = RadioButtons(value='Cap at Percentile',\n",
    "                                 options=['Cap at Percentile', 'Remove Outliers'], margin=leftm())\n",
    "    outlier_lp = FloatText(value=1, width='50px', margin=leftm())\n",
    "    outlier_up = FloatText(value=99, width='50px', margin=leftm())\n",
    "    outlierb = Button(description='Run', button_style='success', width='100px', margin=leftm(30))\n",
    "    \n",
    "    row1 = Box([Label('Select Column: ', layout=Layout(width='200px')), outlier_select, Label('Method: ', margin=leftm(30)),\n",
    "                outlier_radio], layout=row_layout)\n",
    "    row2 = Box([Label('Lower Percentile: ', layout=Layout(width='200px')), outlier_lp, \n",
    "                Label('Upper Percentile: ', margin=leftm(30), layout=Layout(width='200px')),\n",
    "                outlier_up, outlierb], layout=row_layout)\n",
    "    outlierb.on_click(handle_outlier)\n",
    "    return Box([row1, row2], layout=Layout(**col_layout), height='100px')\n",
    "    \n",
    "# functions\n",
    "def handle_outlier(b):\n",
    "    '''Handle outliers.'''\n",
    "    clear_output()\n",
    "    method = 'capped' if outlier_radio.value == 'Cap at Percentile' else 'remove'\n",
    "    col = outlier_select.value\n",
    "    \n",
    "    print('\\nBefore Transformation')\n",
    "    print('Data Shape: {}'.format(mld.shape()))\n",
    "    print('Value Range of {}: ({}, {})'.format(col, mld.data[col].min(), mld.data[col].max()))\n",
    "    mld.handle_outlier(col, method, outlier_lp.value, outlier_up.value, True)\n",
    "    print('\\nAfter Transformation')\n",
    "    print('Data Shape: {}'.format(mld.shape()))\n",
    "    print('Value Range of {}: ({}, {})'.format(col, mld.data[col].min(), mld.data[col].max()))\n",
    "    print('\\nSummary Statistics')\n",
    "    display(mld.get_summary('dtype'))\n",
    "    logger.info('handle outlier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Convert date columns\n",
    "\n",
    "# widgets\n",
    "def make_pdate():\n",
    "    '''Make widgets for converting dates.'''\n",
    "    global pdate_select, pdateb, pdate_to, pdate_pattern, pdate_toggle, pdateb, pdateb2, pdate_ref, \\\n",
    "        col1, col21, col22, pdate_unit\n",
    "    date_cols = mld.get_header('datetime', sort=True)\n",
    "    pdate_height = np.min([300, np.max([len(date_cols) * 15, 200])])\n",
    "    pdate_select = SelectMultiple(options=list(sorted(date_cols)), height='{}px'.format(pdate_height))\n",
    "    pdate_to = Dropdown(height='30px', width='200px', margin=leftm(),\n",
    "                        options=['year', 'month', 'day', 'hour', 'minute', 'second', 'dayofyear',\n",
    "                                 'weekofyear', 'days_in_month', 'date', 'time', 'weekday',\n",
    "                                 'weekday_name', 'quarter', 'is_month_start', 'is_month_end',\n",
    "                                 'is_quarter_start', 'is_quarter_end', 'str'])\n",
    "    pdate_pattern = Text(value='%Y-%m-%d', width='150px', margin=leftm())\n",
    "    pdateb = Button(description='Convert Dates', button_style='success')\n",
    "    pdateb2 = Button(description='Compute Difference', button_style='success')\n",
    "    \n",
    "    pdate_ref = Dropdown(options=['today'] + date_cols, value='today', height='30px', width='200px',\n",
    "                         margin=leftm())\n",
    "    pdate_toggle = ToggleButtons(value='Convert', options=['Convert', 'Date Diff'])\n",
    "    pdate_unit = Dropdown(options=['D', 'h', 'm', 's', 'ms'], value='D', height='30px',\n",
    "                          width='100px', margin=leftm())\n",
    "    \n",
    "    col1 = VBox([Label(\"Select Date Columns: \"), pdate_select])\n",
    "    \n",
    "    col21 = VBox([HBox([pdate_toggle], margin='0px 0px 20px 0px'),\n",
    "                 HBox([Label(\"Convert to: \", layout=Layout(width='200px')), pdate_to], margin='0px 0px 20px 0px'),\n",
    "                 HBox([Label(\"Regex Pattern (only for 'str'): \", layout=Layout(width='200px')), pdate_pattern],\n",
    "                 margin='0px 0px 20px 0px'),\n",
    "                 pdateb], layout=Layout(margin=leftm(30), justify_content='flex-end',\n",
    "                                    height=pdate_select.height, display='flex'))\n",
    "    \n",
    "    col22 = VBox([HBox([pdate_toggle], margin='0px 0px 20px 0px'),\n",
    "                  HBox([Label(\"Reference Date: \", layout=Layout(width='200px')), pdate_ref], margin='0px 0px 20px 0px'),\n",
    "                  HBox([Label(\"Units: \"), pdate_unit], margin='0px 0px 20px 0px'),\n",
    "                  pdateb2], layout=Layout(margin=leftm(30), justify_content='flex-end',\n",
    "                                    height=pdate_select.height, display='flex'))\n",
    "    \n",
    "    pdateb.on_click(convert_date)\n",
    "    pdateb2.on_click(date_diff)\n",
    "    pdate_toggle.observe(redisplay_pdate, names='value')\n",
    "    return HBox([col1, col21])\n",
    "    \n",
    "def redisplay_pdate(chg):\n",
    "    '''Switch between date_convert and date_diff'''\n",
    "    global pros\n",
    "    pros.close()\n",
    "    if pdate_toggle.value == 'Convert':\n",
    "        pros = HBox([col1, col21])\n",
    "    else:\n",
    "        pros = HBox([col1, col22])        \n",
    "    display(pros)\n",
    "\n",
    "\n",
    "# function\n",
    "def convert_date(b):\n",
    "    '''Convert dates.'''\n",
    "    clear_output()\n",
    "    new_names = ['{}.{}'.format(name, pdate_to.value) for name in list(pdate_select.value)]\n",
    "    mld.data[new_names] = mld.convert_dates(list(pdate_select.value), to=pdate_to.value,\n",
    "                                            pattern=pdate_pattern.value, inplace=False)\n",
    "    if pdate_to.value == 'str':\n",
    "        mld.infer_categorical(new_names)\n",
    "    print('\\nBefore Transformation')\n",
    "    print('Data Types:\\n{}'.format(mld.data[list(pdate_select.value)].dtypes.reset_index().values))\n",
    "    display(mld.data[list(pdate_select.value)].head())\n",
    "    print('After Transformation - new columns are created: ')\n",
    "    print('Data Types:\\n{}'.format(mld.data[new_names].dtypes.reset_index().values))\n",
    "    display(mld.data[new_names].head())\n",
    "    print('\\nSummary Statistics')\n",
    "    display(mld.get_summary('dtype'))\n",
    "\n",
    "def date_diff(b):\n",
    "    '''Take date diff'''\n",
    "    clear_output()\n",
    "    ref_date = pdate_ref.value\n",
    "    new_names = ['{} - {}'.format(name, ref_date) for name in list(pdate_select.value)]\n",
    "    if ref_date == 'today':\n",
    "        ref_date = datetime.datetime.today()\n",
    "    mld.data[new_names] = mld.date_diff(pdate_select.value, ref_date, pdate_unit.value, inplace=False)\n",
    "    print('\\nBefore Transformation')\n",
    "    display(mld.data[list(pdate_select.value)].head())\n",
    "    print('After Transformation - new columns are created: ')\n",
    "    display(mld.data[new_names].head())\n",
    "    print('\\nSummary Statistics')\n",
    "    display(mld.get_summary('dtype'))\n",
    "    logger.info('convert date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Handle missing value\n",
    "\n",
    "# widgets\n",
    "def make_miss():\n",
    "    global fillna_num, fillna_cat, fillna_group, fillnab, dropna_axis, dropna_thrh, dropnab\n",
    "    fillna_num = Dropdown(options=['median', 'mean', 'zero'], value='median', height='30px',\n",
    "                          width='150px', margin=leftm())\n",
    "    fillna_cat = Text(value='unknown', width='150px', margin=leftm(15))\n",
    "    fillna_group = Dropdown(height='30px', width='200px', margin=leftm(),\n",
    "                            options=[None] + mld.get_header(['category', 'object']))\n",
    "    fillnab = Button(description=\"Fill Nulls\", button_style='success', margin=leftm(280), width='100px')\n",
    "    fillnab.on_click(fillna)\n",
    "\n",
    "    dropna_axis = RadioButtons(value='columns', options=['rows', 'columns'], margin=leftm())\n",
    "    dropna_thrh = FloatText(value=90, width='100px', margin=leftm())\n",
    "    dropnab = Button(description=\"Drop Nulls\", button_style='success', margin=leftm(130), width='100px')\n",
    "    dropnab.on_click(dropna)\n",
    "    \n",
    "    row1 = Box([Label('Drop: ', layout=Layout(width='200px')), dropna_axis, \n",
    "                Label('when percent of nulls > ', layout=Layout(width='200px'), margin=leftm(20)),\n",
    "                dropna_thrh, dropnab], layout=row_layout)    \n",
    "    row2 = Box([Label('Otherwise fill with:', layout=Layout(width='200px'))], layout=row_layout)\n",
    "    row3 = Box([Label('Numerical Fill: ', layout=Layout(width='200px')), fillna_num,\n",
    "                Label('Numerical Fill Group by: ', margin=leftm(20), layout=Layout(width='200px')), fillna_group], layout=row_layout)\n",
    "    row4 = Box([Label('Category Fill: ', layout=Layout(width='200px')), fillna_cat, fillnab], layout=row_layout)\n",
    "\n",
    "    return Box([row1, row2, row3, row4], layout=Layout(**col_layout), height='180px')\n",
    "    \n",
    "\n",
    "# function\n",
    "def fillna(b):\n",
    "    clear_output()\n",
    "    mld.fill_na(cat_fill=fillna_cat.value, num_fill=fillna_num.value, groupby=fillna_group.value)\n",
    "    display(mld.get_summary('dtype'))\n",
    "    logger.info('fill null')\n",
    "    \n",
    "def dropna(b):\n",
    "    clear_output()\n",
    "    print('\\nData Shape Before: {}'.format(mld.shape()))\n",
    "    mld.drop_na(axis=int(dropna_axis.value == 'columns'), threshold=1 - dropna_thrh.value / 100)\n",
    "    print('Data Shape After: {}'.format(mld.shape()))\n",
    "    print('\\nSummary Statistics')\n",
    "    display(mld.get_summary('dtype'))\n",
    "    logger.info('drop null')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parse string value\n",
    "\n",
    "def make_pstr():\n",
    "    global pstr_select, pstr_method, pstr_mtdp, pstrb\n",
    "    cols = mld.get_header(['category', 'object'])\n",
    "    pstr_height = str(np.min([300, np.max([len(cols) * 15, 200])])) + \"px\"\n",
    "    pstr_select = SelectMultiple(options=cols, height='{}px'.format(pstr_height))\n",
    "    pstr_method = Dropdown(height='30px', width='150px', margin=leftm())\n",
    "    pstr_method.options=['capitalize', 'contains', 'count', 'endswith', 'extract',\n",
    "                        'find', 'findall', 'join', 'len', 'lower', 'repeat',\n",
    "                         'slice', 'split', 'startswith', 'strip', 'upper',\n",
    "                        'isalnum', 'isalpha', 'isdigit', 'isspace', 'islower', 'isupper', 'isnumeric',\n",
    "                        'isdecimal']\n",
    "    pstr_mtdp = Text(width='150px', margin=leftm())\n",
    "    pstrb = Button(description=\"Parse String\", button_style='success', width='100px')\n",
    "    pstrb.on_click(pstr)\n",
    "    \n",
    "    col1 = VBox([Label(\"Select Columns: \", layout=Layout(width='200px')), pstr_select])\n",
    "    col2 = VBox([HBox([Label('Select String Method: ',layout=Layout(width='200px')), pstr_method], margin='0px 0px 40px 0px'),\n",
    "                 HBox([Label('Additional Input: ', layout=Layout(width='200px')), pstr_mtdp],\n",
    "                      margin='0px 0px 50px 0px'), pstrb],\n",
    "                layout=Layout(margin=leftm(30), justify_content='flex-end', height=pstr_height,\n",
    "                              display='flex'))\n",
    "    return HBox([col1, col2])\n",
    "\n",
    "\n",
    "def pstr(b):\n",
    "    clear_output()\n",
    "    \n",
    "    if pstr_method.value in ['split', 'findall']:\n",
    "        new_names = []\n",
    "        for col in pstr_select.value:\n",
    "            res = mld.data[col].astype(str).str.split(pstr_mtdp.value, expand=True)\n",
    "            names = ['{}.{}'.format(col, i) for i in res.columns]\n",
    "            mld.data[names] = res\n",
    "            new_names += names\n",
    "    else:\n",
    "        new_names = ['{}.{}'.format(name, pstr_method.value) for name in pstr_select.value]\n",
    "        if len(pstr_mtdp.value.strip()) > 0:\n",
    "            mtdp = pstr_mtdp.value\n",
    "            try:\n",
    "                mtdp = int(mtdp)\n",
    "            except:\n",
    "                pass\n",
    "            res = mld.parse_str(list(pstr_select.value), pstr_method.value, True, False, mtdp)\n",
    "            \n",
    "        else:\n",
    "            res = mld.parse_str(list(pstr_select.value), pstr_method.value)\n",
    "        \n",
    "        if len(res.shape) == 1:\n",
    "            mld.data[new_names[0]] = res\n",
    "        else:\n",
    "            mld.data[new_names] = res\n",
    "        \n",
    "    print('\\nBefore Transformation')\n",
    "    display(mld.data[list(pstr_select.value)].head())\n",
    "    print('After Transformation - new columns are created: ')\n",
    "    display(mld.data[new_names].head())\n",
    "    print('\\nSummary Statistics')\n",
    "    display(mld.get_summary('dtype'))\n",
    "    logger.info('parse string')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pros_mapping = {'Drop Columns': make_drop, 'Filter Rows': make_filter, 'Convert Dates': make_pdate,\n",
    "                'Handle Missing Value': make_miss, 'Parse String': make_pstr,\n",
    "                'Handle Outlier': make_outlier}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# override ipythonwidgets build in function \n",
    "\n",
    "def _get_min_max_value(min, max, value=None, step=None):\n",
    "    \"\"\"Return min, max, value given input values with possible None.\"\"\"\n",
    "    if value is None:\n",
    "        if not max > min:\n",
    "            raise ValueError('max must be greater than min: (min={0}, max={1})'.format(min, max))\n",
    "        diff = max - min\n",
    "        value = min + (diff / 2)\n",
    "        # Ensure that value has the same type as diff\n",
    "        if not isinstance(value, type(diff)):\n",
    "            value = min + (diff // 2)\n",
    "    elif min is None and max is None:\n",
    "        # if not isinstance(value, Real):\n",
    "        #     raise TypeError('expected a real number, got: %r' % value)\n",
    "        if not value:\n",
    "            t = type(value)\n",
    "            min, max = (t(0), t(1))\n",
    "        elif value > 0:\n",
    "            min, max = (0, np.max([10*value, 10]))\n",
    "        else:\n",
    "            min, max = (np.min([10*value, -10]), 0)\n",
    "    else:\n",
    "        raise ValueError('unable to infer range, value from: ({0}, {1}, {2})'.format(min, max, value))\n",
    "    if step is not None:\n",
    "        # ensure value is on a step\n",
    "        r = (value - min) % step\n",
    "        value = value - r\n",
    "    return min, max, value\n",
    "\n",
    "interaction._get_min_max_value = _get_min_max_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Run single model\n",
    "\n",
    "model_options = {'LinearRegression': 'ols',\n",
    "            'Ridge': 'ridge',\n",
    "            'Lasso': 'lasso',\n",
    "            'ElasticNet': 'enet',\n",
    "            'BayesianRidge': 'bayes',\n",
    "#             'RANSACRegressor': 'ransac',\n",
    "            'SVR': 'svr',\n",
    "            'KNeighborsRegressor': 'knnrgr',\n",
    "            'DecisionTreeRegressor': 'dtrgr',\n",
    "            'AdaBoostRegressor': 'ab',\n",
    "            'GradientBoostingRegressor': 'gbrgr',\n",
    "            'RandomForestRegressor': 'rfrgr',\n",
    "            'ExtraTreesRegressor': 'ert',\n",
    "            'BaggingRegressor': 'bag'}\n",
    "\n",
    "model_args = {\n",
    "    'ols': {'fit_intercept': True, 'normalize': False, 'n_jobs': 1},\n",
    "    'ridge': {'alpha': 1.0, 'fit_intercept': True, 'normalize': False},\n",
    "    'lasso': {'alpha': 1.0, 'fit_intercept': True, 'normalize': False},\n",
    "    'enet': {'alpha':1.0, 'l1_ratio': 0.5, 'fit_intercept': True, 'normalize': False},\n",
    "    'bayes': {'alpha_1': 1e-06, 'alpha_2': 1e-06, 'lambda_1': 1e-06, 'lambda_2': 1e-06, \n",
    "              'compute_score': False, 'fit_intercept': True, 'normalize': False},\n",
    "#     'ransac': {'max_trials': 100, 'stop_probability': 0.99},\n",
    "    'svr': {'kernel': ['linear', 'poly', 'rbf', 'sigmoid', 'precomputed'], 'degree': 3,\n",
    "            'gamma': 'auto', 'coef0': 0.0, 'C': 1.0, 'epsilon': 0.1,'shrinking': True},\n",
    "    'knnrgr': {'n_neighbors': 5, 'weights': ['uniform', 'distance'],\n",
    "            'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
    "            'leaf_size': 30, 'p': 2, 'metric': 'minkowski', 'n_jobs': 1},\n",
    "    'dtrgr': {'criterion': 'mse', 'splitter': 'best', 'max_depth': 5, 'min_samples_split': 10,\n",
    "           'min_samples_leaf': 15, 'min_weight_fraction_leaf': 0.0},\n",
    "    'ab': {'n_estimators': 50, 'learning_rate': 1.0, 'loss': 'linear'},\n",
    "    'gbrgr': {'loss': 'ls', 'learning_rate': 0.1, 'n_estimators': 100, 'subsample': 1.0,\n",
    "           'min_samples_split': 2, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.0,\n",
    "           'max_depth': 3, 'alpha': 0.9},\n",
    "    'rfrgr': {'n_estimators': 10, 'criterion': 'mse', 'max_depth': 20, 'min_samples_split': 2,\n",
    "           'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.0, 'max_features': 'auto',\n",
    "           'bootstrap': True, 'oob_score': False, 'n_jobs': 1},\n",
    "    'ert': {'n_estimators': 10, 'criterion': 'mse', 'max_depth': 20, 'min_samples_split': 2,\n",
    "            'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.0, 'max_features': 'auto',\n",
    "            'bootstrap': False, 'oob_score': False, 'n_jobs': 1},\n",
    "    'bag': {'n_estimators': 10, 'max_samples': 1.0, 'max_features': 1.0, 'bootstrap': True,\n",
    "            'bootstrap_features': False, 'oob_score': False, 'n_jobs': 1}}\n",
    "\n",
    "metric_options = {'R2 Score': 'r2', 'Mean Squared Error': 'mse', 'Mean Absolute Error': 'mae', \n",
    "                  'Median Absolute Error': 'meae', 'Explained Variance Score': 'evs'}\n",
    "\n",
    "# widgets\n",
    "model_dropcat = Checkbox(value=True, margin=leftm(), width='50px')\n",
    "model_dropthrh = IntSlider(value=500, max=500, margin=leftm())\n",
    "\n",
    "model_seed = IntText(value=0, width='150px', margin=leftm())\n",
    "model_split = FloatSlider(value=0.7, min=0, max=1, step=0.01, width='600px', margin=leftm())\n",
    "model_select = Dropdown(options=model_options, value='dtrgr', height='30px', margin=leftm(),\n",
    "                        width='200px')\n",
    "\n",
    "model_metric = SelectMultiple(options=metric_options, value=('r2',), height='90px', margin=leftm(),\n",
    "                              width='200px')\n",
    "\n",
    "model_prog = FloatProgress(value=0, min=0, max=10, step=1, description='Progress:',\n",
    "                           margin=leftm(600), width='200px')\n",
    "\n",
    "modelb = Button(description=\"Run Model\", button_style='success', width='100px', margin=leftm(150))\n",
    "model_save = Button(description=\"Save Results\", button_style='warning', width='100px', margin=leftm(150))\n",
    "\n",
    "def make_single():\n",
    "    '''Make widgets for single model.'''\n",
    "    global model_target, model_features\n",
    "    \n",
    "    mlm.define_regressor(model_name=model_select.value, **model_args[model_select.value])\n",
    "    print(mlm.model)\n",
    "    \n",
    "    model_target = Dropdown(options=mld.get_header(['float', 'int'], sort=True), height='30px',\n",
    "                            margin=leftm(), width='200px')\n",
    "\n",
    "    columns = mld.get_header(['float', 'int', 'category', 'object'], sort=True)\n",
    "    features_height = np.min([300, np.max([len(columns) * 12, 100])])\n",
    "    model_features = SelectMultiple(options=columns, margin=leftm(),\n",
    "                                    height='{}px'.format(features_height))\n",
    "\n",
    "    rows = []\n",
    "    rows.append(Box([Label('Target Variable: ', layout=Layout(width='200px')), model_target], layout=row_layout))\n",
    "    rows.append(Box([Label('Independent Variables: ', layout=Layout(width='200px')), model_features], layout=row_layout))\n",
    "    rows.append(Box([Label('Evaluation Metric: ', layout=Layout(width='200px')), model_metric], layout=row_layout))\n",
    "    rows.append(Box([Label('Select Model: ', layout=Layout(width='200px')), model_select, model_save, modelb], layout=row_layout))\n",
    "    rows.append(Box([model_prog], layout=row_layout))\n",
    "    rows.append(Box([model_toggle_param], margin='0px 0px 20px 0px'))\n",
    "\n",
    "    return Box(rows, layout=Layout(**col_layout), height='{}px'.format(300 + features_height))\n",
    "\n",
    "# functions\n",
    "def model_chg(chg):\n",
    "    '''Listen to model change event, and re-define regressor and create model parameter Box.'''\n",
    "    global model_param_displayed, w\n",
    "    clear_output()\n",
    "    w.close()\n",
    "    mlm.define_regressor(model_name=model_select.value)\n",
    "    print(mlm.model)\n",
    "    \n",
    "    args = model_args[model_select.value]\n",
    "    w = interactive(set_params, **args)\n",
    "    w = modify_box_widget(w)\n",
    "    if model_param_displayed:\n",
    "        display(w)\n",
    "\n",
    "def set_params(**args):\n",
    "    '''Set model parameters and print.'''\n",
    "    mlm.model.set_params(**args)\n",
    "    print(mlm.model)\n",
    "\n",
    "def modify_box_widget(w):\n",
    "    '''Modify the model parameter box widget.'''\n",
    "    children = []\n",
    "    for child in w.children:\n",
    "        child.margin = leftm()\n",
    "        if hasattr(child, 'description'):\n",
    "            desc = child.description\n",
    "            child.description = ''\n",
    "            children.append(Box([Label('{}: '.format(desc), layout=Layout(width='200px')), child], layout=row_layout))\n",
    "        else:\n",
    "            children.append(child)\n",
    "    return Box(children, layout=Layout(**col_layout), height='{}px'.format(40 * len(w.children)))\n",
    "\n",
    "model_select.observe(model_chg, names='value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Run Multiple Model\n",
    "\n",
    "# widgets\n",
    "model_select2 = SelectMultiple(options=model_options, height='200px', margin=leftm(),\n",
    "                               width='200px')\n",
    "\n",
    "model_metric2 = Dropdown(options=metric_options, value='r2', height='30px', margin=leftm(),\n",
    "                         width='200px')\n",
    "\n",
    "model_toggle_param = Button(description=\"Toggle Model Settings\", button_style='success',\n",
    "                            width='170px')\n",
    "    \n",
    "def make_multiple():\n",
    "    '''Make widgets for multiple models'''\n",
    "    global model_target, model_features\n",
    "\n",
    "    #mlm.define_regressor(model_name='all')\n",
    "    mlm.define_regressor(model_name='run_all_regressors')\n",
    "    model_target = Dropdown(options=mld.get_header(['float', 'int'], sort=True), height='30px',\n",
    "                            margin=leftm(), width='200px')\n",
    "\n",
    "    columns = mld.get_header(['float', 'int', 'category', 'object'], sort=True)\n",
    "    features_height = np.min([300, np.max([len(columns) * 12, 100])])\n",
    "    model_features = SelectMultiple(options=columns, margin=leftm(),\n",
    "                                    height='{}px'.format(features_height))\n",
    "\n",
    "    rows = []\n",
    "    rows.append(Box([Label('Target Variable: ', layout=Layout(width='200px')), model_target], layout=row_layout))\n",
    "    rows.append(Box([Label('Independent Variables: ', layout=Layout(width='200px')), model_features], layout=row_layout))\n",
    "    rows.append(Box([Label('Evaluation Metric: ', layout=Layout(width='200px')), model_metric2], layout=row_layout))\n",
    "    rows.append(Box([Label('Select Models: ', layout=Layout(width='200px')), model_select2], layout=row_layout))\n",
    "    rows.append(Box([modelb], margin=leftm(500)))\n",
    "    rows.append(Box([model_prog], layout=row_layout))\n",
    "    rows.append(model_toggle_param)\n",
    "\n",
    "    return Box(rows, layout=Layout(**col_layout), height='{}px'.format(450 + features_height))\n",
    "\n",
    "\n",
    "# functions\n",
    "model_param_displayed = False\n",
    "def toggle_param(b):\n",
    "    '''Toggle model parameters.'''\n",
    "    global model_param_displayed, w\n",
    "\n",
    "    if model_param_displayed:\n",
    "        w.close()\n",
    "    else:\n",
    "        if mode_select.value == 'Run Single Model':\n",
    "            args = model_args[model_select.value]\n",
    "            w = interactive(set_params, **args)\n",
    "            w = modify_box_widget(w)\n",
    "        else:\n",
    "            w = get_multiple_params()\n",
    "        display(w)\n",
    "    model_param_displayed = not model_param_displayed\n",
    "\n",
    "def get_multiple_params():\n",
    "    '''Create parameter Box for multiple models.'''\n",
    "    rows = []\n",
    "    for model in model_select2.value:\n",
    "        args = model_args[model]\n",
    "        w = interactive(set_params_model, model=fixed(model), **args)\n",
    "        w = modify_box_widget(w)\n",
    "        name = re.match('(\\w+)\\(' , str(mlm.models[model])).group(1)\n",
    "        rows.append(HTML('<b>{}</b>'.format(name), margin='20px 0px 10px 0px'))\n",
    "        rows.append(w)\n",
    "    return VBox(rows)\n",
    "\n",
    "def set_params_model(model, **args):\n",
    "    '''Set parameters for a specific model and print.'''\n",
    "    mlm.models[model].set_params(**args)\n",
    "    print(mlm.models[model])\n",
    "\n",
    "model_toggle_param.on_click(toggle_param)\n",
    "  \n",
    "\n",
    "def run_model(b):\n",
    "    clear_output()\n",
    "    \n",
    "#     perf_log(client='ADS-OPAL', module='Opal-regression', submodule='build_model', tag_def='version-1.0', user=user)\n",
    "    \n",
    "    if len(model_features.value) == 0:\n",
    "        raise ValueError(\"Please select independent variables.\")\n",
    "    \n",
    "    model_prog.value = 0\n",
    "    model_prog.description = 'Start...'\n",
    "    features = list(np.setdiff1d(model_features.value, [model_target.value]))\n",
    "    all_cols = features + [model_target.value]\n",
    "    if model_dropcat.value:\n",
    "        mld.drop_cat_cols(all_cols, threshold=model_dropthrh.value)\n",
    "        all_cols = list(np.intersect1d(all_cols, mld.get_header()))\n",
    "\n",
    "    if mld.data[all_cols].isnull().sum().sum() > 0:\n",
    "        mld.fill_na(all_cols)\n",
    "\n",
    "    mld.create_dummy_data(features)\n",
    "    \n",
    "    global XX_train, yy_train, XX_test, yy_test\n",
    "\n",
    "    XX_train, yy_train, XX_test, yy_test = \\\n",
    "        mlm.split_random(mld.dummies, mld.data[model_target.value],\n",
    "                         train_ratio=model_split.value)\n",
    "    \n",
    "\n",
    "    if mode_select.value == 'Run Single Model':\n",
    "        mlm.fit_model(XX_train, yy_train, indep_cols=features) \n",
    "        \n",
    "        pred_name = \"predicted_\" + model_target.value\n",
    "        mld.data[pred_name] = mlm.predict(mld.dummies)\n",
    "        pred_error_name = \"error_predicted_\" + model_target.value\n",
    "        mld.data[pred_error_name] = mlm.predict(mld.dummies) - mld.data[model_target.value]\n",
    "      \n",
    "        model_prog.value = 5\n",
    "        model_prog.description = 'Progress.'\n",
    "        #show_results(X_train, y_train, X_test, y_test)\n",
    "        model_prog.description = 'Done!'\n",
    "        model_prog.value = 10\n",
    "        logger.info('ran single model')\n",
    "    else:\n",
    "        model_prog.value = 5\n",
    "        model_prog.description = 'Progress.'\n",
    "        res = mlm.model_comparison(XX_train, yy_train, XX_test, yy_test, features,\n",
    "                                   list(model_select2.value))\n",
    "        res = pd.Series(res).reset_index().round(4)\n",
    "        res.columns = ['Model', model_metric2.value]\n",
    "        res.sort_values(model_metric2.value, ascending=False, inplace=True)\n",
    "        print('\\nModel Performance')\n",
    "        display(res)\n",
    "        model_prog.description = 'Done!'\n",
    "        model_prog.value = 10\n",
    "        logger.info('ran multiple models')\n",
    "\n",
    "def show_results(X_train, y_train, X_test, y_test):\n",
    "    '''Show prediction results and performance scores.'''\n",
    "    global train_scores, test_scores, fi, coef \n",
    "\n",
    "    # performance score\n",
    "    print(\"performance score\")\n",
    "    print(\"On Training Set\")\n",
    "    pred_train = mlm.predict(X_train)\n",
    "    #train_scores = mlm.eval_model(y_train, pred_train, metric=model_metric.value)\n",
    "    train_scores = mlm.eval_model(ytrue=y_train, ypred=pred_train, metric_list=model_metric.value)\n",
    "    train_scores = pd.DataFrame({'metric': model_metric.value, 'score': train_scores}).round(4)\n",
    "    display(train_scores)\n",
    "\n",
    "    print(\"On Testing Set\")\n",
    "    pred_test = mlm.predict(X_test)\n",
    "    #test_scores = mlm.eval_model(y_test, pred_test, metric=model_metric.value)\n",
    "    test_scores = mlm.eval_model(ytrue=y_test, ypred=pred_test, metric_list=model_metric.value)\n",
    "    test_scores = pd.DataFrame({'metric': model_metric.value, 'score': test_scores}).round(4)\n",
    "    display(test_scores)\n",
    "\n",
    "    if hasattr(mlm.model, 'feature_importances_'):\n",
    "        fi = mlm.check_feature_importance(group=True).round(4)\n",
    "        print('\\nFeature Importance')\n",
    "        display(fi)\n",
    "\n",
    "    if model_select.value == 'dtrgr':\n",
    "       img_bi = mlm.decision_tree_plot()\n",
    "       display(SVG(img_bi))\n",
    "\n",
    "    if model_select.value == 'ols':\n",
    "        coef = pd.DataFrame({'Feature': mlm.dummy_indep_cols, 'Coef': mlm.model.coef_})\n",
    "        pos_mask = coef['Coef'] > 0\n",
    "        pos_coef = coef[pos_mask].sort_values('Coef', ascending=False)\n",
    "        neg_coef = coef[~pos_mask].sort_values('Coef')\n",
    "        display('Positive Coefficients', pos_coef)\n",
    "        display('Negative Coefficients', neg_coef)\n",
    "\n",
    "    # make prediction\n",
    "    print(\"Predictions on Test Data\")\n",
    "    display(pd.concat([pred_test, y_test, mld.data.ix[y_test.index, mlm.indep_cols]], axis=1))\n",
    "\n",
    "def save_results(b):\n",
    "    try:\n",
    "        if not os.path.exists('results'):\n",
    "            os.makedirs('results')\n",
    "        train_scores.to_csv('results/train_scores.csv', index=False)\n",
    "        test_scores.to_csv('results/test_scores.csv', index=False)\n",
    "        fi.to_csv('results/feature_importance,csv', index=False)\n",
    "        if model_select.value == 'ols':\n",
    "            coef.to_csv('results/coefficients.csv')\n",
    "        elif model_select.value == 'dtrgr':\n",
    "            png = mlm.decision_tree_plot('png')\n",
    "            with open('results/decision_tree_plot.png', 'wb') as f:\n",
    "                f.write(png)\n",
    "        print('Done!')\n",
    "    except Exception as e:\n",
    "        print(str(e))\n",
    "\n",
    "modelb.on_click(run_model)\n",
    "model_save.on_click(save_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Select Mode\n",
    "\n",
    "mode_select = ToggleButtons(options=['Run Single Model', 'Run Multiple Models'], value='Run Multiple Models', margin=leftm())\n",
    "\n",
    "display(HBox([Label('Mode: '), mode_select], layout=Layout(margin='0px 0px 30px 0px')))\n",
    "\n",
    "\n",
    "mode_mapping = {'Run Single Model': make_single, 'Run Multiple Models': make_multiple}\n",
    "mode = HTML('')\n",
    "w = HTML('')\n",
    "\n",
    "rows = []\n",
    "rows.append(Box([Label('Drop Categorical Column if Too Many Distinct Values: ', layout=Layout(width='600px')), model_dropcat,\n",
    "                 Label('Threshold: '), model_dropthrh], layout=row_layout))\n",
    "rows.append(Box([Label('Random Seed: ', layout=Layout(width='200px')), model_seed], layout=row_layout))\n",
    "rows.append(Box([Label('Proportion for Training: ', layout=Layout(width='200px')), model_split], layout=row_layout))\n",
    "\n",
    "display(Box(rows, layout=Layout(**col_layout), height='120px', margin='0px 0px 10px 0px'))\n",
    "\n",
    "def switch_mode(chg):\n",
    "    '''Switch between modeling mode.'''\n",
    "    global mode\n",
    "    clear_output()\n",
    "    mode.close()\n",
    "    mode = mode_mapping[mode_select.value]()\n",
    "    display(mode)\n",
    "\n",
    "mode_select.observe(switch_mode, names='value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#ipython_vars = ['In', 'Out', 'exit', 'quit', 'get_ipython', 'ipython_vars']\n",
    "#sorted([(x, sys.getsizeof(globals().get(x))) for x in dir() if not x.startswith('_') and x not in sys.modules and x not in ipython_vars], key=lambda x: x[1], reverse=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#sys.getsizeof(globals().get(MLData))\n",
    "#dir()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model Result (only for single model)\n",
    "- model result in testing data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Select Graph\n",
    "\n",
    "# widgets\n",
    "Result_chart_select = ToggleButtons(\n",
    "    options=['Visualize Prediction', 'Display Predictions'],\n",
    "    tooltips=['Visualize Prediction outside training set, Confidence Interval and real values', 'Display Predictions'],\n",
    "    value='Visualize Prediction', \n",
    "    margin=leftm()\n",
    ")\n",
    "\n",
    "display(HBox([Label('Model Result Type: ', layout=Layout(width='200px')), Result_chart_select], layout=Layout(margin='0px 0px 30px 0px')))\n",
    "\n",
    "# functions\n",
    "grph = HTML('')\n",
    "\n",
    "def Result_switch_chart(chg):\n",
    "    '''Switch between graph type.'''\n",
    "    global grph\n",
    "    clear_output()\n",
    "    if (grph != None):\n",
    "        grph.close()\n",
    "    #grph.close()\n",
    "    grph = Result_graph_mapping[Result_chart_select.value]()\n",
    "    display(grph)\n",
    "\n",
    "Result_chart_select.observe(Result_switch_chart, names='value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Confidence Interval chart\n",
    "\n",
    "# widgets\n",
    "def make_Confidence_Interval():\n",
    "    '''create widgets for Confidence_Interval'''\n",
    "    #global pie_filter2, pie_select2, pie_limit2, group_less_freq2, pieb2\n",
    "    \n",
    "    global pie_select2, pieb2\n",
    "\n",
    "    #pie_filter2 = Text(value='', width='500px')\n",
    "    pie_select2 = Dropdown(options=mld.get_header(sort=True), height='30px', width='200px',\n",
    "                          margin=leftm())\n",
    "    #pie_limit2 = IntText(value=20, width='70px')\n",
    "    #group_less_freq2 = Checkbox(value=False)\n",
    "    pieb2 = Button(description=\"Plot\", button_style='success', width='70px', height='30px',\n",
    "                  margin=leftm(20))\n",
    "    \n",
    "    row0 = Box([HTML('<h4> Visualize outsample prediction and confidence interval</h4>')],\n",
    "                layout=Layout(display='flex', flex_flow='row', align_items='center',\n",
    "                              justify_content='center', width='90%'))\n",
    "    row1 = Box([pieb2], layout=row_layout)\n",
    "\n",
    "    scatter_chart = Box([row0, row1], layout=Layout(**col_layout),\n",
    "                    height='160px')\n",
    "\n",
    "    pie_select2.observe(plot_Confidence_Interval, names='value')\n",
    "    pieb2.on_click(plot_Confidence_Interval)\n",
    "    return scatter_chart\n",
    "\n",
    "# functions\n",
    "def gradientBoostingRegr_band(clf_outside, X_train, y_train, X_test, y_test):\n",
    "    '''clf must be gradient boosting regressor'''\n",
    "    ## for upper bound\n",
    "    clf = clone(clf_outside)\n",
    "    alpha = 0.95\n",
    "    clf.set_params(loss='quantile')\n",
    "    clf.set_params(alpha=alpha)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_upper = clf.predict(X_test)\n",
    "    \n",
    "    ## for lower bound\n",
    "    clf.set_params(alpha=1.0 - alpha)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_lower = clf.predict(X_test)\n",
    "    \n",
    "    ## for prediction\n",
    "    clf.set_params(loss='ls')\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    return y_pred, y_upper, y_lower\n",
    "    \n",
    "    \n",
    "def plot_Confidence_Interval(chg):\n",
    "    '''plot the Confidence Interval chart'''\n",
    "    clear_output()\n",
    "    if ((type(mlm.model) != sklearn.ensemble.forest.RandomForestRegressor) and (type(mlm.model) != sklearn.ensemble.gradient_boosting.GradientBoostingRegressor)):\n",
    "        return None\n",
    "    \n",
    "    forest = mlm.model\n",
    "    #X_train, y_train, X_test, y_test = \\\n",
    "    #    mlm.split_random(mld.dummies, mld.data[model_target.value],\n",
    "    #                     train_ratio=model_split.value)\n",
    "               \n",
    "    \n",
    "    if (type(forest) == sklearn.ensemble.forest.RandomForestRegressor):\n",
    "        #forest.fit(X_train, y_train)\n",
    "        y_hat = forest.predict(XX_test)\n",
    "        #V_IJ_calibrated = fci.random_forest_error(forest,X_train, X_test)\n",
    "        V_IJ_calibrated = random_forest_error(forest,XX_train, XX_test)\n",
    "\n",
    "        yerr=np.sqrt(V_IJ_calibrated)\n",
    "        y_mid = y_hat\n",
    "\n",
    "    if (type(forest) == sklearn.ensemble.gradient_boosting.GradientBoostingRegressor):\n",
    "        y_hat, y_upper, y_lower = gradientBoostingRegr_band(clf_outside=mlm.model, X_train=XX_train, \n",
    "                                                            y_train=yy_train, X_test=XX_test, y_test=yy_test)\n",
    "        y_mid = 0.5 * (y_upper + y_lower)\n",
    "        yerr = y_upper - y_mid\n",
    "            \n",
    "    confidence_band = go.Scatter(\n",
    "                x=list(yy_test),\n",
    "                y=list(y_mid),\n",
    "                error_y=dict(\n",
    "                    type='data',\n",
    "                    array=list(yerr),\n",
    "                    visible=True\n",
    "                ),\n",
    "                mode='markers',\n",
    "                name='confidence_band'\n",
    "            )\n",
    "\n",
    "    real_value = go.Scatter(\n",
    "                x=list(yy_test),\n",
    "                y=list(yy_test),\n",
    "                mode='markers',\n",
    "                name='real_value'\n",
    "            )\n",
    "    \n",
    "    prediction = go.Scatter(\n",
    "                x=list(yy_test),\n",
    "                y=list(y_hat),\n",
    "                mode='markers',\n",
    "                name='prediction'\n",
    "            )\n",
    "        \n",
    "    data = [confidence_band, real_value, prediction]\n",
    "    \n",
    "    layout = go.Layout(xaxis=dict(title='ytest'),\n",
    "                   yaxis=dict(title='ypred')\n",
    "                   )\n",
    "\n",
    "    figp = go.Figure(data=data, layout=layout)\n",
    "    #figp = go.Figure(data=[trace0, trace1, fx, observations], layout=layout)\n",
    "    \n",
    "    iplot(figp)\n",
    "    logger.info('plotted Confidence Interval')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def display_predictions_on_test():    \n",
    "    # make prediction\n",
    "    #print(\"Predictions on Test Data\")\n",
    "    forest = mlm.model\n",
    "    #X_train, y_train, X_test, y_test = \\\n",
    "    #    mlm.split_random(mld.dummies, mld.data[model_target.value],\n",
    "    #                     train_ratio=model_split.value)\n",
    "    \n",
    "    #show_results(X_train=XX_train, y_train=yy_train, X_test=XX_test, y_test=yy_test)\n",
    "    \n",
    "    try:\n",
    "        show_results(X_train=XX_train, y_train=yy_train, X_test=XX_test, y_test=yy_test)\n",
    "    except:\n",
    "        print(\"Capture error: need to run model first, and Graphviz executables are on your systems' path\")\n",
    "    #display(pd.concat([pred_test, y_test, mld.data.ix[y_test.index, mlm.indep_cols]], axis=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Result_graph_mapping = {'Visualize Prediction': make_Confidence_Interval, 'Display Predictions': display_predictions_on_test}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. What's Behind the Scene"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Take a look at the Python script (click \"show/hide code\" and see the first code block). You will see \n",
    "\n",
    "```python\n",
    "from mltemplate.mldata import MLData\n",
    "from mltemplate.mlmodel import MLModel\n",
    "mld = MLData()\n",
    "mlm = MLModel()\n",
    "```\n",
    "\n",
    "Here we created 'mld' as an instance of the MLData class, which is responsible for data cleaning, parsing and transforming, etc, while 'mlm' is an instance of the MLModel class, which is responsible for modeling building, predicting, and evaluating model performance, etc.\n",
    "\n",
    "For MLData you can try some basic usages like\n",
    "\n",
    "```python\n",
    "print(mld.head(20))  # check the top 20 rows\n",
    "print(mld.get_header())  # check column headers\n",
    "print(mld.ct_freq('col_A'))  # count frequencies for each unique value in col_A\n",
    "print(mld.get_summary())  # get the summary statistics\n",
    "print(mld.query('col_A < 5'))  # filter rows by sql-like criterion\n",
    "```\n",
    "\n",
    "For MLModel you can try things like\n",
    "\n",
    "```python\n",
    "mlm.define_regressor(model_name='dtrgr')  # set the regressor to be a decision tree model\n",
    "mlm.fit_model(X, y, indep_cols=['colA', 'colB', 'colC'])  # fit a model using X as the input data, y as target variable, and 'colA', 'colB', 'colC' as the independent columns.\n",
    "mlm.predict(X)  # make predictions using X as the input data\n",
    "mlm.eval_model(ytrue, ypred, metric='r2')  # evaluate model performance by comparing the true target 'ytrue' with the prediction 'ypred', using R-squared as the metric.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix: Some Keyboard Shortcuts:\n",
    "\n",
    "- **ctrl + shift + p**: bring up the entire keyboard shortcut list \n",
    "\n",
    "- In command mode (when selected cell border is in <span style='color:blue'>**blue**</span>)\n",
    "    - **enter**: enter edit mode\n",
    "    - **esc**: exit edit mode\n",
    "    - **ctrl-enter**: execute the current cell\n",
    "    - **b**: insert a cell below\n",
    "    - **a**: insert a cell above\n",
    "    - **dd**: delete current cell\n",
    "\n",
    "\n",
    "- In edit model (when selected cell border is in <span style='color:green'>**green**</span>)\n",
    "    - move cursor on any function or module name, and press **shift+tab**: this will bring up the function signitures (can press the \"+\" sign to expand).\n",
    "    - **tab**: auto-complete\n",
    "    - select a block and **tab/shift-tab**: indent/de-indent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logger.info('loaded widgets')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
